import { relations, sql } from "drizzle-orm";
import {
  index,
  integer,
  primaryKey,
  real,
  sqliteTable,
  text,
  unique,
} from "drizzle-orm/sqlite-core";
import { user } from "./auth-schema";

// Re-export auth tables from auto-generated schema
export * from "./auth-schema";

// Add your custom tables below this line

/**
 * Tracks devices that have accessed the app.
 * A device is identified by a client-generated UUID stored in localStorage.
 * This is separate from sessions - devices persist across logins/logouts.
 */
export const userDevice = sqliteTable(
  "user_devices",
  {
    id: text("id").primaryKey(), // UUID generated server-side
    userId: text("user_id")
      .notNull()
      .references(() => user.id, { onDelete: "cascade" }),
    clientId: text("client_id").notNull(), // The device ID from localStorage
    deviceName: text("device_name"), // Friendly name like "Chrome on macOS"
    browser: text("browser"),
    os: text("os"),
    deviceType: text("device_type"), // mobile, tablet, or desktop
    lastActiveAt: integer("last_active_at", { mode: "timestamp_ms" }),
    createdAt: integer("created_at", { mode: "timestamp_ms" })
      .default(sql`(cast(unixepoch('subsecond') * 1000 as integer))`)
      .notNull(),
  },
  (t) => [unique("user_client_unique").on(t.userId, t.clientId)],
);

export const userDeviceRelations = relations(userDevice, ({ one }) => ({
  user: one(user, {
    fields: [userDevice.userId],
    references: [user.id],
  }),
}));

/**
 * Stores book metadata for syncing across devices.
 * The fileHash (xxhash64) is the canonical sync identifier - same EPUB file
 * on different devices will have the same hash and auto-merge.
 */
export const book = sqliteTable(
  "books",
  {
    id: text("id").primaryKey(), // UUID generated server-side
    userId: text("user_id")
      .notNull()
      .references(() => user.id, { onDelete: "cascade" }),
    fileHash: text("file_hash").notNull(), // xxhash64 hex - the sync key

    // Book metadata
    title: text("title").notNull(),
    author: text("author").notNull(),
    fileSize: integer("file_size").notNull(),

    // R2 references (null until uploaded)
    epubR2Key: text("epub_r2_key"),
    coverR2Key: text("cover_r2_key"),

    // Additional metadata (JSON blob for flexibility)
    // Contains: publisher, language, isbn, description, etc.
    metadata: text("metadata", { mode: "json" }).$type<{
      publisher?: string;
      language?: string;
      isbn?: string;
      description?: string;
      publishedDate?: string;
      [key: string]: unknown;
    }>(),

    // Timestamps for sync
    createdAt: integer("created_at", { mode: "timestamp_ms" })
      .default(sql`(cast(unixepoch('subsecond') * 1000 as integer))`)
      .notNull(),
    updatedAt: integer("updated_at", { mode: "timestamp_ms" })
      .default(sql`(cast(unixepoch('subsecond') * 1000 as integer))`)
      .notNull(),
    deletedAt: integer("deleted_at", { mode: "timestamp_ms" }), // soft delete
  },
  (t) => [
    // Prevent duplicates per user - this is the merge key
    unique("user_file_hash_unique").on(t.userId, t.fileHash),
    // Index for efficient sync queries
    index("idx_books_user_updated").on(t.userId, t.updatedAt),
  ],
);

export const bookRelations = relations(book, ({ one }) => ({
  user: one(user, {
    fields: [book.userId],
    references: [user.id],
  }),
}));

/**
 * Append-only log of reading progress events.
 *
 * Each entry represents a "reading position snapshot" from a specific device at a specific time.
 * This structure supports:
 * - Per-device ordering via (deviceId, clientSeq)
 * - Global ordering via serverSeq (auto-increment)
 * - Conflict resolution using "latest serverSeq wins"
 * - Reading stats derivation from timestamps
 *
 * The log captures all navigation events including:
 * - Normal reading progress
 * - Footnote jumps and returns
 * - Search navigation
 * - TOC navigation
 *
 * Post-processing can filter/interpret these events as needed.
 */
export const readingProgressLog = sqliteTable(
  "reading_progress_log",
  {
    // serverSeq as INTEGER PRIMARY KEY gives us auto-increment atomically
    // This is the global ordering key for sync
    serverSeq: integer("server_seq").primaryKey({ autoIncrement: true }),

    // External ID for client references (UUID generated by client)
    id: text("id").notNull().unique(),

    userId: text("user_id")
      .notNull()
      .references(() => user.id, { onDelete: "cascade" }),
    fileHash: text("file_hash").notNull(), // Book identifier (not FK to allow progress before book sync)
    deviceId: text("device_id")
      .notNull()
      .references(() => userDevice.id, { onDelete: "cascade" }),

    // Position data
    spineIndex: integer("spine_index").notNull(),
    scrollProgress: real("scroll_progress").notNull(), // 0.0-1.0

    // Client-side ordering - monotonic per device per book
    clientSeq: integer("client_seq").notNull(),
    clientTimestamp: integer("client_timestamp", {
      mode: "timestamp_ms",
    }).notNull(),

    // Server timestamp for sync queries (auto-set on insert)
    serverTimestamp: integer("server_timestamp", { mode: "timestamp_ms" })
      .default(sql`(cast(unixepoch('subsec') * 1000 as integer))`)
      .notNull(),
  },
  (t) => [
    // For fetching progress for a specific book
    index("idx_progress_user_book").on(t.userId, t.fileHash),
    // For sync pagination - fetch all progress since a serverSeq
    index("idx_progress_user_server_seq").on(t.userId, t.serverSeq),
    // For per-device ordering queries
    index("idx_progress_device_seq").on(t.deviceId, t.clientSeq),
  ],
);

export const readingProgressLogRelations = relations(
  readingProgressLog,
  ({ one }) => ({
    user: one(user, {
      fields: [readingProgressLog.userId],
      references: [user.id],
    }),
    device: one(userDevice, {
      fields: [readingProgressLog.deviceId],
      references: [userDevice.id],
    }),
  }),
);

/**
 * Generic sync data table for HLC-based sync.
 * Stores all synced entities with their HLC timestamps for last-write-wins resolution.
 */
export const syncData = sqliteTable(
  "sync_data",
  {
    id: text("id").notNull(),
    tableName: text("table_name").notNull(),
    userId: text("user_id")
      .notNull()
      .references(() => user.id, { onDelete: "cascade" }),
    entityId: text("entity_id"), // For entity-scoped sync (e.g., bookId for highlights)
    hlc: text("hlc").notNull(), // Hybrid Logical Clock timestamp
    deviceId: text("device_id").notNull(), // Client device ID
    isDeleted: integer("is_deleted", { mode: "boolean" })
      .default(false)
      .notNull(),
    serverTimestamp: integer("server_timestamp", { mode: "timestamp_ms" })
      .default(sql`(cast(unixepoch('subsec') * 1000 as integer))`)
      .notNull(),
    data: text("data", { mode: "json" }).notNull(), // JSON blob of the entity data
  },
  (t) => [
    primaryKey({ columns: [t.tableName, t.userId, t.id] }),
    // Index for pulling changes
    index("idx_sync_pull").on(t.tableName, t.userId, t.serverTimestamp),
    // Index for entity-scoped pulls
    index("idx_sync_entity").on(
      t.tableName,
      t.userId,
      t.entityId,
      t.serverTimestamp,
    ),
  ],
);

export const syncDataRelations = relations(syncData, ({ one }) => ({
  user: one(user, {
    fields: [syncData.userId],
    references: [user.id],
  }),
}));
